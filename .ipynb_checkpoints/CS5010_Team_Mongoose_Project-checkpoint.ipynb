{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating approaches to handle missing data in context of machine learning problems\n",
    "\n",
    "### Abhijith Mandya\n",
    "### Rohan Bapat\n",
    "### Sally Gao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import RandomForestRegressor from scikitlearn to predict missing values using Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import RandomForestRegressor from scikitlearn to predict missing values using Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import train_test_split for cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LogisticRegression from scikitlearn to classify test values using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import accuracy_score from scikitlearn to determine accuracy of test prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import RandomForestClassifier from scikitlearn to classify test values using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT DATA\n",
    "#--------------\n",
    "\n",
    "# Add path of your data on your local drive\n",
    "df = pd.read_csv(\"train.csv\", nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "#-----------------\n",
    "\n",
    "# Remove outliers. Those rides that were greater than 6 hours\n",
    "df = df[df.trip_duration < 21600]\n",
    "\n",
    "# Remove erroneous observations where passenger_count = 0 \n",
    "df = df[df.passenger_count > 0]\n",
    "\n",
    "# Convert string into datetime variable\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create minute column\n",
    "df['pickup_minute'] = df['pickup_datetime'].dt.minute\n",
    "df['dropoff_minutes'] = df['dropoff_datetime'].dt.minute\n",
    "\n",
    "# Create hour column\n",
    "df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "df['dropoff_hour'] = df['dropoff_datetime'].dt.hour\n",
    "\n",
    "# Create day of week column\n",
    "df['pickup_dow'] = df['pickup_datetime'].dt.weekday\n",
    "df['dropoff_dow'] = df['dropoff_datetime'].dt.weekday\n",
    "\n",
    "# Create day of month column\n",
    "df['pickup_dom'] = df['pickup_datetime'].dt.day\n",
    "df['dropoff_dom'] = df['dropoff_datetime'].dt.day\n",
    "\n",
    "# Create month column\n",
    "df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "df['dropoff_month'] = df['dropoff_datetime'].dt.month\n",
    "\n",
    "# Map 'Y' and 'N' in 'store_and_fwd_flag' as 1 and 0\n",
    "store_and_fwd_map = {'Y':1,'N':0}\n",
    "df = df.copy()\n",
    "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].map(store_and_fwd_map)\n",
    "\n",
    "# Convert numerical day of week into textual format\n",
    "week = {0:\"Sun\", 1:\"Mon\", 2:\"Tue\", 3:\"Wed\", 4:\"Thur\", 5:\"Fri\", 6:\"Sat\"}\n",
    "df[\"pickup_weekday\"] = df[\"pickup_dow\"].map(week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EXPLORATORY ANALYSIS\n",
    "#-----------------------\n",
    "\n",
    "# PART 1 - Estimate the manhattan distance\n",
    "df['manhattan_distance'] = abs(df.pickup_longitude-df.dropoff_longitude)*68.703 + abs(df.pickup_latitude-df.dropoff_latitude)*55.243\n",
    "\n",
    "# Print mean and median distance travlled\n",
    "print(\"Mean distance travelled is \" + str(np.around(np.mean(df['manhattan_distance']),decimals=2)))\n",
    "print(\"Median distance travelled is \" + str(np.round(np.median(df['manhattan_distance']),decimals=2)))\n",
    "\n",
    "# Plot histogram of Manhattan distance of all trips taken by cabs\n",
    "plt.figure()\n",
    "plt.title(\"Manhattan Distance in Miles\",fontsize=24 )\n",
    "plt.hist(df['manhattan_distance'], 40, range=[0,20])\n",
    "plt.xlabel(\"Manhattan Distance in Miles\", fontsize=16 )\n",
    "plt.ylabel(\"No. of Taxis\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "# PART 2 - Visualise variation in taxi pick up time by hour\n",
    "fig2 = sns.countplot(x=\"pickup_hour\", data=df, color = \"b\")\n",
    "fig2.set(xlabel='Hour of Day', ylabel='No. of Taxis Hailed', title = \"Taxi's Hailed by the Hour\")\n",
    "sns.plt.show()\n",
    "\n",
    "# PART 3 - Visualise variation in taxi pick up day by day of week\n",
    "\n",
    "df2 = df.sort_values('pickup_dow', axis = 0)\n",
    "df2 = df2.reset_index(drop= True)\n",
    "\n",
    "fig3 = sns.countplot(x=\"pickup_weekday\", data=df2, color = \"b\")\n",
    "fig3.set(xlabel='Day of Week', ylabel='No. of Taxis Hailed', title = \"Taxi's hailed by the day\")\n",
    "sns.plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MISSING DATA\n",
    "#-----------------\n",
    "\n",
    "# Create missing data\n",
    "random.seed(123)\n",
    "\n",
    "# Insert nan values in pickup_hour\n",
    "nan_pickup_hours = df['pickup_hour'].sample(round(df.shape[0]/3.3)).index\n",
    "df.loc[nan_pickup_hours,'pickup_hour']=np.nan\n",
    "\n",
    "# Insert nan values in dropoff_longitude\n",
    "nan_dropoff_longitude = df['dropoff_longitude'].sample(round(df.shape[0]/4.1)).index\n",
    "df.loc[nan_dropoff_longitude,'dropoff_longitude']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# APPROACHES TO HANDLE MISSING DATA\n",
    "#--------------------------------------\n",
    "\n",
    "# Approach 1 - Delete rows with missing values\n",
    "# Pass only the dataframe as argument\n",
    "# Returns clean dataframe and the % of rows dropped\n",
    "\n",
    "def approach1_rem_msg(messy_df):\n",
    "    \n",
    "    # Drop entire row containing missing values\n",
    "    clean_df = messy_df.dropna()\n",
    "    \n",
    "    # Calculate % of rows dropped\n",
    "    rows_dropped = 1 - clean_df.shape[0]/messy_df.shape[0]\n",
    "    return clean_df, rows_dropped\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Approach 2 - Impute missing values\n",
    "# The following function imputes the missing values with mean/median/mode according to arguments passed\n",
    "# User also has to pass as list the names of columns which have missing values \n",
    "# Call function  - approach2_impute_metric(<df>,<\"mean\">/<\"median\">/<\"mode\">,[<'missingcolname1'>,<'missingcolname2'])\n",
    "# Returns cleaned df and list of imputed values for all columns\n",
    "\n",
    "def approach2_impute_metric(messy_df, metric, colnames):\n",
    "    clean_df = messy_df.copy()    \n",
    "    missing_list = []\n",
    "    \n",
    "    # Impute mean\n",
    "    if metric==\"mean\":\n",
    "        for col in colnames:\n",
    "            \n",
    "            # Caluclate mean value of required column\n",
    "            imputenum = messy_df[col].mean()\n",
    "            \n",
    "            # Calculate number of observations having missing value\n",
    "            missing_count = messy_df[col].isnull().sum()\n",
    "            \n",
    "            # Create a list of imputed missing values\n",
    "            missing_list.append([imputenum]*missing_count)\n",
    "            \n",
    "            # Impute mean in the missing fields\n",
    "            clean_df[col] = messy_df[col].fillna(imputenum)            \n",
    "\n",
    "    if metric==\"median\":\n",
    "        for col in colnames:\n",
    "            \n",
    "            # Caluclate median value of required column\n",
    "            imputenum = messy_df[col].median()\n",
    "            \n",
    "            # Calculate number of observations having missing value\n",
    "            missing_count = messy_df[col].isnull().sum()  \n",
    "            \n",
    "            # Create a list of imputed missing vales\n",
    "            missing_list.append([imputenum]*missing_count)\n",
    "            \n",
    "            # Impute median in the missing fields\n",
    "            clean_df[col] = messy_df[col].fillna(imputenum)\n",
    "    \n",
    "    if metric==\"mode\":\n",
    "        for col in colnames:\n",
    "            \n",
    "             # Caluclate mode value of required column\n",
    "            imputenum = messy_df[col].mode()\n",
    "            \n",
    "            # Calculate number of observations having missing valu\n",
    "            missing_count = messy_df[col].isnull().sum\n",
    "            \n",
    "            # Get positions of missing values\n",
    "            missing_pos = clean_df[col].isnull()\n",
    "            \n",
    "            # In case of multiple modes, randomly allocate the modes across missing fields\n",
    "            clean_df.loc[clean_df[col].isnull(),col] = np.random.choice(imputenum)\n",
    "            \n",
    "            # Create missing_list\n",
    "            missing_list.append(clean_df.loc[missing_pos,col].tolist())    \n",
    "        \n",
    "    return clean_df, missing_list\n",
    " \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Approach 3 - Predict missing values\n",
    "# The following function predicts missing values using Linear Regression or Random Forests\n",
    "# User also has to pass as list the names of columns which have missing values \n",
    "# Call function  - approach2_impute_metric(<df>,<\"Linear Regression\">/<\"Random Forests\">,[<'missingcolname1'>,<'missingcolname2'])\n",
    "# Returns cleaned df and list of imputed values for all columns\n",
    "    \n",
    "def approach3_predict_msg(messy_df, metric, colnames):\n",
    "    \n",
    "    # Create X_df of predictor columns\n",
    "    X_df = messy_df.drop(colnames, axis = 1)\n",
    "    \n",
    "    # Create Y_df of predicted columns\n",
    "    Y_df = messy_df[colnames]\n",
    "        \n",
    "    # Create empty dataframes and list\n",
    "    Y_pred_df = pd.DataFrame(columns=colnames)\n",
    "    Y_missing_df = pd.DataFrame(columns=colnames)\n",
    "    missing_list = []\n",
    "    \n",
    "    # Loop through all columns containing missing values\n",
    "    for col in messy_df[colnames]:\n",
    "    \n",
    "        # Number of missing values in the column\n",
    "        missing_count = messy_df[col].isnull().sum()\n",
    "        \n",
    "        # Separate train dataset which does not contain missing values\n",
    "        messy_df_train = messy_df[~messy_df[col].isnull()]\n",
    "        \n",
    "        # Create X and Y within train dataset\n",
    "        msg_cols_train_df = messy_df_train[col]\n",
    "        messy_df_train = messy_df_train.drop(colnames, axis = 1)\n",
    "\n",
    "        # Create test dataset, containing missing values in Y    \n",
    "        messy_df_test = messy_df[messy_df[col].isnull()]\n",
    "        \n",
    "        # Separate X and Y in test dataset\n",
    "        msg_cols_test_df = messy_df_test[col]\n",
    "        messy_df_test = messy_df_test.drop(colnames,axis = 1)\n",
    "\n",
    "        # Copy X_train and Y_train\n",
    "        Y_train = msg_cols_train_df.copy()\n",
    "        X_train = messy_df_train.copy()\n",
    "        \n",
    "        # Linear Regression model\n",
    "        if metric == \"Linear Regression\":\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train,Y_train)\n",
    "            print(\"R-squared value is: \" + str(model.score(X_train, Y_train)))\n",
    "          \n",
    "        # Random Forests regression model\n",
    "        elif metric == \"Random Forests\":\n",
    "            model = RandomForestRegressor(n_estimators = 100 , oob_score = True)\n",
    "            model.fit(X_train,Y_train) \n",
    "            \n",
    "#             importances = model.feature_importances_\n",
    "#             indices = np.argsort(importances)\n",
    "#             features = X_train.columns\n",
    "            \n",
    "#             print(\"Missing values in\"+ col)\n",
    "#             #plt.title('Feature Importances')\n",
    "#             plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "#             plt.yticks(range(len(indices)), features) ## removed [indices]\n",
    "#             plt.xlabel('Relative Importance')\n",
    "#             plt.show()\n",
    "        \n",
    "        X_test = messy_df_test.copy()\n",
    "        \n",
    "        # Predict Y_test values by passing X_test as input to the model\n",
    "        Y_test = model.predict(X_test)\n",
    "        \n",
    "        Y_test_integer = pd.to_numeric(pd.Series(Y_test),downcast='integer')\n",
    "        \n",
    "        # Append predicted Y values to known Y values\n",
    "        Y_complete = Y_train.append(Y_test_integer)\n",
    "        Y_complete = Y_complete.reset_index(drop = True)\n",
    "        \n",
    "        # Update list of missing values\n",
    "        missing_list.append(Y_test.tolist())\n",
    "        \n",
    "        Y_pred_df[col] = Y_complete\n",
    "        Y_pred_df = Y_pred_df.reset_index(drop = True)\n",
    "    \n",
    "    # Create cleaned up dataframe\n",
    "    clean_df = X_df.join(Y_pred_df)\n",
    "    \n",
    "    return clean_df,missing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "#-----------------------------\n",
    "\n",
    "# Clean data before inputting to prediction model\n",
    "def clean_performance_measure_df(df2):\n",
    "    \n",
    "    # Set trip duration cutoff in minutes (for 0/1 classification)\n",
    "    trip_duration_cutoff_mins = 20\n",
    "    \n",
    "    df2['trip_duration_encoded'] = 0\n",
    "    \n",
    "    # Encode trip duration according to cutoff minutes criteria\n",
    "    df2.loc[df2['trip_duration']>=trip_duration_cutoff_mins*60,'trip_duration_encoded'] = 1\n",
    "    df2.loc[df2['trip_duration']<trip_duration_cutoff_mins*60,'trip_duration_encoded'] = 0\n",
    "    \n",
    "    # Drop variables not required for prediction\n",
    "    df2 = df2.drop(['dropoff_minutes','dropoff_hour',\n",
    "                    'dropoff_dow','dropoff_dom','dropoff_month','trip_duration','dropoff_longitude','dropoff_latitude'], axis = 1)\n",
    "    \n",
    "    # Drop missing values (if any)\n",
    "    df2.dropna(inplace=True)\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPARE PERFORMANCE OF APPROACHES TO HANDLE MISSING VALUES\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Accuracy function which returns accuracy of prediction\n",
    "def accuracy_determination(df2,algo, Y_col):\n",
    "    df = clean_performance_measure_df(df2)\n",
    "    y = df[Y_col]\n",
    "    X = df.drop(Y_col, axis = 1)\n",
    "    \n",
    "    # Split into test and train data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    \n",
    "    # Classify trip duration using Logistic Regression\n",
    "    if algo == \"Logistic Regression\":\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "    # Classify trip duration using Random Forests\n",
    "    elif algo == \"Random Forests\":\n",
    "        model = RandomForestClassifier(n_estimators = 100 , oob_score = True)\n",
    "        model.fit(X_train,y_train)\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)\n",
    "        features = X_train.columns\n",
    "\n",
    "        #plt.title('Feature Importances')\n",
    "        plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "        plt.yticks(range(len(indices)), features) ## removed [indices]\n",
    "        plt.xlabel('Relative Importance')\n",
    "        plt.show()\n",
    "        \n",
    "# Predict accuracy of model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# APPROACHES TO MISSING DATA\n",
    "#-------------------------------\n",
    "\n",
    "# # Test the approaches to missing data\n",
    "\n",
    "df_test = df.drop(['id','pickup_datetime','dropoff_datetime','pickup_weekday','manhattan_distance'], axis = 1)\n",
    "df_test = df_test.head(100000)\n",
    "\n",
    "# # Call function to clean missing data\n",
    "\n",
    "# # Approach 1 - delete rows containing missing values \n",
    "test_pred1, rows_dropped = approach1_rem_msg(df_test)\n",
    "\n",
    "# # Get performance measure of Approach 1\n",
    "test_pred1_logistic_accuracy = accuracy_determination(test_pred1,\"Logistic Regression\",'trip_duration_encoded')\n",
    "test_pred1_rf_accuracy = accuracy_determination(test_pred1,\"Random Forests\",'trip_duration_encoded')\n",
    "\n",
    "# #----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Approach 2 - Impute missing values\n",
    "\n",
    "# # Part a - Impute with mean\n",
    "test_pred2a, imputed_values2a = approach2_impute_metric(df_test,\"mean\",['dropoff_longitude','pickup_hour'])\n",
    "# # Get performance measure of Approach 2a\n",
    "test_pred2a_logistic_accuracy = accuracy_determination(test_pred2a,\"Logistic Regression\",'trip_duration_encoded')\n",
    "test_pred2a_rf_accuracy = accuracy_determination(test_pred2a,\"Random Forests\",'trip_duration_encoded')\n",
    "\n",
    "# # Part b - Impute with median\n",
    "test_pred2b, imputed_values2b = approach2_impute_metric(df_test,\"median\",['dropoff_longitude','pickup_hour'])\n",
    "# # Get performance measure of Approach 2b\n",
    "test_pred2b_logistic_accuracy = accuracy_determination(test_pred2b,\"Logistic Regression\",'trip_duration_encoded')\n",
    "test_pred2b_rf_accuracy = accuracy_determination(test_pred2b,\"Random Forests\",'trip_duration_encoded')\n",
    "\n",
    "# # Part c - Impute with mode\n",
    "test_pred2c, imputed_values2c = approach2_impute_metric(df_test,\"mode\",['dropoff_longitude','pickup_hour'])\n",
    "# # Get performance measure of Approach 2c\n",
    "test_pred2c_logistic_accuracy = accuracy_determination(test_pred2c,\"Logistic Regression\",'trip_duration_encoded')\n",
    "test_pred2c_rf_accuracy = accuracy_determination(test_pred2c,\"Random Forests\",'trip_duration_encoded')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # Approach 3 - Predict missing values\n",
    "\n",
    "# #Part a - Predict using linear regression\n",
    "test_pred3a, predicted_values3a = approach3_predict_msg(df_test,\"Linear Regression\",['dropoff_longitude','pickup_hour'])\n",
    "# # Get performance measure of Approach 3a\n",
    "test_pred3a_logistic_accuracy = accuracy_determination(test_pred3a,\"Logistic Regression\",'trip_duration_encoded')\n",
    "test_pred3a_rf_accuracy = accuracy_determination(test_pred3a,\"Random Forests\",'trip_duration_encoded')\n",
    "\n",
    "# Part b - Predict using Random Forests\n",
    "test_pred3b, predicted_values3b = approach3_predict_msg(df_test,\"Random Forests\",['dropoff_longitude','pickup_hour'])\n",
    "# # Get performance measure of Approach 3b\n",
    "test_pred3b_logistic_accuracy = accuracy_determination(test_pred3b,\"Logistic Regression\",'trip_duration_encoded')\n",
    "test_pred3b_rf_accuracy = accuracy_determination(test_pred3b,\"Random Forests\",'trip_duration_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparisons_df = pd.DataFrame(columns = ['Approach', 'Accuracy - Logistic Regression', 'Accuracy - Random Forests'],\n",
    "                              data =[['Remove missing rows',test_pred1_logistic_accuracy,test_pred1_rf_accuracy],\n",
    "                                     ['Impute - mean',test_pred2a_logistic_accuracy,test_pred2a_rf_accuracy],\n",
    "                                     ['Impute - median',test_pred2b_logistic_accuracy,test_pred2b_rf_accuracy],\n",
    "                                     ['Impute - mode',test_pred2c_logistic_accuracy,test_pred2c_rf_accuracy],\n",
    "                                     ['Predict - Linear Regression',test_pred3a_logistic_accuracy,test_pred3a_rf_accuracy],\n",
    "                                     ['Predict - Random Forests',test_pred3b_logistic_accuracy,test_pred3b_rf_accuracy]])\n",
    "comparisons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare missing value replacement approaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import missingno as msno\n",
    "\n",
    "# Get number of values replaced\n",
    "pickup_replaced = len(imputed_values2a[1])\n",
    "long_replaced = len(imputed_values2a[0])\n",
    "\n",
    "# Get info for imputed mean values\n",
    "mean_pickup = imputed_values2a[1][1]\n",
    "mean_dropoff = imputed_values2a[0][1]\n",
    "\n",
    "# Get info for imputed median values\n",
    "median_pickup = imputed_values2b[1][1]\n",
    "median_dropoff = imputed_values2b[0][1]\n",
    "\n",
    "# Get info for imputed modes\n",
    "mode_pickup = set(imputed_values2c[1])\n",
    "mode_pickupr = [round(elem, 2) for elem in mode_pickup]\n",
    "num_pickup_modes = len(set(imputed_values2c[1]))\n",
    "mode_dropoff = set(imputed_values2c[0])\n",
    "mode_dropoffr = [round(elem, 2) for elem in mode_dropoff]\n",
    "num_dropoff_modes = len(set(imputed_values2c[0]))\n",
    "\n",
    "# make 4 buttons\n",
    "button1 = Button(description=\"Delete rows with missing values\",\n",
    "           layout=Layout(width='50%', height='50px'))\n",
    "button2 = Button(description=\"Impute metric: Mean\",\n",
    "                layout=Layout(width='50%', height='50px'))\n",
    "button3 = Button(description=\"Impute metric: Median\",\n",
    "                layout=Layout(width='50%', height='50px'))\n",
    "button4 = Button(description=\"Impute metric: Mode\",\n",
    "                layout=Layout(width='50%', height='50px'))\n",
    "button5 = Button(description=\"Predict values: Linear Regression\",\n",
    "                layout=Layout(width='50%', height='50px'))\n",
    "button6 = Button(description=\"Predict values: Random Forests\",\n",
    "                layout=Layout(width='50%', height='50px'))\n",
    "display(button1, button2, button3, button4, button5, button6)\n",
    "\n",
    "# define button calls\n",
    "\n",
    "def button1Clicked(b):\n",
    "    clear_output()\n",
    "    msno.matrix(df)\n",
    "    msno.matrix(test_pred1)\n",
    "    \n",
    "def button2Clicked(b):\n",
    "    clear_output()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))  \n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Mean Pickup Hour: \"+str(round(mean_pickup,2))+\"\\n# of Values Replaced: \"+str(pickup_replaced), fontsize=22)\n",
    "    plt.hist(test_pred2a['pickup_hour'], 15, color=\"#2980B9\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    plt.axvspan(mean_pickup-.06, mean_pickup+.06, color='red', alpha=0.5)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Mean Dropoff Longitude: \"+str(round(mean_dropoff,2))+\"\\n# of Values Replaced: \"+str(long_replaced), fontsize=22)\n",
    "    plt.hist(test_pred2a['dropoff_longitude'], 10, range=[-74.4, -73.6], color=\"#FBC02D\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Dropoff Longitude\", fontsize=16)\n",
    "    plt.axvspan(mean_dropoff-.0025, mean_dropoff+.0025, color='red', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('impute_mean.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def button3Clicked(b):\n",
    "    clear_output()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))  \n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Median Pickup Hour: \"+str(round(median_pickup,2))+\"\\n# of Values Replaced: \"+str(pickup_replaced), fontsize=22)\n",
    "    plt.hist(test_pred2b['pickup_hour'], 15, color=\"#2980B9\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    plt.axvspan(median_pickup-.06, median_pickup+.06, color='red', alpha=0.5)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Median Dropoff Longitude: \"+str(round(mean_dropoff,2))+\"\\n# of Values Replaced: \"+str(long_replaced), fontsize=22)\n",
    "    plt.hist(test_pred2b['dropoff_longitude'], 10, range=[-74.5, -73.5], color=\"#FBC02D\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Dropoff Longitude\", fontsize=16)\n",
    "    plt.axvspan(median_dropoff-.0025, median_dropoff+.0025, color='red', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('impute_median.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def button4Clicked(b):\n",
    "    clear_output()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Pickup Hour\\n# of Modes: \"+str(num_pickup_modes)+\" -- \"+str(mode_pickupr), fontsize=22)\n",
    "    plt.hist(test_pred2c['pickup_hour'], 24, color=\"#2980B9\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    [plt.axvspan(x-.06, x+.06, color='red', alpha=0.5) for x in mode_pickupr]\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Dropoff Longitude\\n# of Modes: \"+str(num_dropoff_modes)+\" -- \"+str(mode_dropoffr), fontsize=22)\n",
    "    plt.hist(test_pred2c['dropoff_longitude'], 10, range=[-74.5, -73.5], color=\"#FBC02D\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Dropoff Longitude\", fontsize=16)\n",
    "    [plt.axvspan(x-.0025, x+.0025, color='red', alpha=0.5) for x in mode_dropoffr]\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('impute_mode.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def button5Clicked(b):\n",
    "    clear_output()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Pickup Hour with Linear Regression\", fontsize=22)\n",
    "    plt.hist(predicted_values3a[1], 15, color=\"#795548\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Dropoff Longitude with Linear Regression\", fontsize=22)\n",
    "    plt.hist(predicted_values3a[0], 15, color=\"#2980B9\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('lin_regression.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def button6Clicked(b):\n",
    "    clear_output()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Pickup Hour with Random Forests\", fontsize=22)\n",
    "    plt.hist(predicted_values3b[1], 15, color=\"#8BC34A\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Dropoff Longitude with Random Forests\", fontsize=22)\n",
    "    plt.hist(predicted_values3b[0], 15, color=\"#FB8C00\", alpha=0.6)\n",
    "    plt.ylabel(\"Frequency\", fontsize=16) \n",
    "    plt.xlabel(\"Pickup Hour\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('random_forests.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# specify which functions to be called when buttons are clicked\n",
    "button1.on_click(button1Clicked)\n",
    "button2.on_click(button2Clicked)\n",
    "button3.on_click(button3Clicked)\n",
    "button4.on_click(button4Clicked)\n",
    "button5.on_click(button5Clicked)\n",
    "button6.on_click(button6Clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
